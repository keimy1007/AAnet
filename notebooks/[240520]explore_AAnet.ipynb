{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目的：AAnetのモデルをとりあえず動かす"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/keimy/git/AAnet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from abc import abstractmethod\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "# ツール\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import tqdm\n",
    "import random\n",
    "import itertools\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# ローカルライブラリのインポート\n",
    "%cd /users/keimy/git/AAnet/\n",
    "%pwd\n",
    "from AAnet_torch.types_ import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseAAnet(nn.Module):\n",
    "    '''\n",
    "    Base class for AAnet variants. Implements functions to calculate barycentric\n",
    "    coordinates, translating between the archetypal space and the feature space, etc.\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        super(BaseAAnet, self).__init__()\n",
    "\n",
    "    def encode(self, input: Tensor) -> List[Tensor]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def decode(self, input: Tensor) -> Any:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, *inputs: Tensor) -> Tensor:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def loss_function(self, *inputs: Any, **kwargs) -> Tensor:\n",
    "        pass\n",
    "\n",
    "\n",
    "    def get_archetypes_latent(self):\n",
    "        return torch.tensor(\n",
    "            np.vstack(\n",
    "                [torch.eye(self.n_archetypes - 1), np.zeros(n_archetypes-1)]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def get_n_simplex(self, n=2, scale=1):\n",
    "        '''\n",
    "        Returns an n-simplex centered at the origin in the feature space\n",
    "        '''\n",
    "        nth = 1/(n-1)*(1-np.sqrt(n)) * np.ones(n-1)\n",
    "        D = np.vstack([np.eye(n-1), nth]) * scale\n",
    "        return torch.tensor(D - np.mean(D, axis=0), dtype=torch.float, device=self.device)\n",
    "\n",
    "    def get_archetypes_data(self):\n",
    "        '''Returns archetypes in the feature domain'''\n",
    "        return self.decode(self.get_n_simplex(self.n_archetypes, self.simplex_scale))\n",
    "\n",
    "    def euclidean_to_barycentric(self, X):\n",
    "        '''\n",
    "        Converts euclidean coordinates to barycentric coordinates wrt a regular simplex\n",
    "        centered the origin scaled by `scale`.\n",
    "\n",
    "        Requires `self.archetypal_simplex` to be fit.\n",
    "        '''\n",
    "        simplex = self.archetypal_simplex\n",
    "\n",
    "        T = torch.zeros((X.shape[1], X.shape[1])).to(self.device)\n",
    "        for i in range(X.shape[1]):\n",
    "            for j in range(X.shape[1]):\n",
    "                T[i,j] = simplex[i,j] - simplex[-1,j]\n",
    "\n",
    "        T_inv =  torch.inverse(T).type(torch.float).to(self.device)\n",
    "        X_bary = torch.einsum('ij,bj->bi', T_inv, X - simplex[-1]).to(self.device)\n",
    "        X_bary = torch.cat([X_bary, (1-torch.sum(X_bary, axis=1, keepdim=True))], axis=1).to(self.device)\n",
    "        return X_bary\n",
    "\n",
    "    def is_in_simplex(self, X_bary):\n",
    "        '''Is True for points that are inside the simplex and False otherise'''\n",
    "        all_non_negative = torch.sum(X_bary >= 0, axis=1) == X_bary.shape[1]\n",
    "        all_convex = torch.sum(X_bary <= 1, axis=1) == X_bary.shape[1]\n",
    "        return  all_non_negative & all_convex\n",
    "\n",
    "    def dist_to_simplex(self, X_bary):\n",
    "        '''\n",
    "        Sums all negative values outside the simplex\n",
    "\n",
    "        TODO: this results in lower loss values on the boundaries of the voronoi regions outside the simplex\n",
    "        '''\n",
    "        return torch.sum(\n",
    "                 torch.where((X_bary < 0),\n",
    "                   torch.abs(X_bary),\n",
    "                   torch.zeros(X_bary.shape, dtype=torch.float).to(self.device)\n",
    "                   ),\n",
    "                 axis=1).to(self.device)\n",
    "\n",
    "    def calc_archetypal_loss(self, archetypal_embedding):\n",
    "        '''\n",
    "        Returns MSE archetypal loss (sum of negative values inside the simplex)\n",
    "        '''\n",
    "        X_bary = self.euclidean_to_barycentric(archetypal_embedding)\n",
    "        return torch.mean(self.dist_to_simplex(X_bary) ** 2)\n",
    "    \n",
    "    def calc_diffusion_extrema_loss(self, archetypal_embedding):\n",
    "        '''\n",
    "        Returns MSE diffusion extrema loss (minimize MSE between diffusion extrema and archetypes)\n",
    "        Diffusion extrema are concatenated to the beginning of each batch as first n_archetypes samples\n",
    "        '''\n",
    "        X_bary = self.euclidean_to_barycentric(archetypal_embedding)\n",
    "        return torch.mean((X_bary[:self.n_archetypes,:] - torch.eye(self.n_archetypes).to(self.device)) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AAnet_VAE(BaseAAnet):\n",
    "    '''\n",
    "    Implements AAnet as a Variational Autoencoder to add noise within the Latent\n",
    "    Space.\n",
    "\n",
    "    Borrows code from: https://github.com/AntixK/PyTorch-VAE/blob/master/models/vanilla_vae.py\n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: List = None,\n",
    "        n_archetypes: int = 4,\n",
    "        layer_widths: List = [128, 128],\n",
    "        activation_out: str = \"tanh\",\n",
    "        simplex_scale: int = 1,\n",
    "        archetypal_weight: float = 1,\n",
    "        kl_loss: str = \"partial\",\n",
    "        device: str = None,\n",
    "        diffusion_extrema=None,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super(AAnet_VAE, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.n_archetypes = n_archetypes\n",
    "        self.layer_widths = layer_widths\n",
    "        self.activation_out = activation_out.lower()\n",
    "        self.simplex_scale = simplex_scale\n",
    "        self.archetypal_weight = archetypal_weight\n",
    "        self.kl_loss = kl_loss\n",
    "        self.diffusion_extrema = diffusion_extrema\n",
    "        if device is None:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        layers = []\n",
    "        # Instantiate encoder\n",
    "        for i, width in enumerate(layer_widths):\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(in_features=input_shape, out_features=width),\n",
    "                    nn.ReLU(),\n",
    "                )\n",
    "            )\n",
    "            input_shape = width\n",
    "\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        # Latent code layer\n",
    "        self.fc_mu = nn.Linear(layer_widths[-1], n_archetypes - 1)\n",
    "        self.fc_var = nn.Linear(layer_widths[-1], n_archetypes - 1)\n",
    "\n",
    "        # Instantiate decoder\n",
    "        self.decoder_input = nn.Linear(n_archetypes - 1, layer_widths[-1])\n",
    "\n",
    "        layers = []\n",
    "        layer_widths.reverse()\n",
    "        for i in range(len(layer_widths) - 1):\n",
    "            # Instantiate first layer\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(in_features=layer_widths[i], out_features=layer_widths[i+1]),\n",
    "                    nn.ReLU(),\n",
    "                    )\n",
    "            )\n",
    "\n",
    "        self.decoder = nn.Sequential(*layers)\n",
    "\n",
    "        # Last decoder layer\n",
    "        if self.activation_out == 'tanh':\n",
    "            act_out = nn.Tanh()\n",
    "        elif self.activation_out in [\"linear\", None]:\n",
    "            act_out = None\n",
    "        else:\n",
    "            raise ValueError('activation_out not recognized')\n",
    "\n",
    "        self.final_layer = nn.Sequential(\n",
    "                            nn.Linear(layer_widths[-1], self.input_shape),\n",
    "                            act_out,\n",
    "        )\n",
    "\n",
    "        self.archetypal_simplex = self.get_n_simplex(self.n_archetypes, scale=self.simplex_scale)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def encode(self, input: Tensor) -> List[Tensor]:\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder(input)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "\n",
    "        return [mu, log_var]\n",
    "\n",
    "    def decode(self, z: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the image space.\n",
    "        :param z: (Tensor) [B x D]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "        result = self.decoder_input(z)\n",
    "        #result = result.view(-1, 512, 2, 2)\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "        return result\n",
    "\n",
    "    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1). This is nescessary because autodiff cannot backpropogate through a\n",
    "        stochastic node (i.e. torch.randn_like). Instead, we sample from the node, and\n",
    "        then treat the output as if it were deterministic (i.e. autodiff doesn't know\n",
    "        that `eps` is changing every time this function is called).\n",
    "\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward(self, input: Tensor, **kwargs) -> List[Tensor]:\n",
    "        mu, log_var = self.encode(input)\n",
    "        archetypal_embedding = mu.clone() # cloned so we can differentiate here twice\n",
    "        z = self.reparameterize(mu, log_var) # sample from the latent space\n",
    "        return  [self.decode(z), input, archetypal_embedding, log_var]\n",
    "\n",
    "    def loss_function(self,\n",
    "                      *args,\n",
    "                      **kwargs) -> dict:\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        mu = args[2]\n",
    "        log_var = args[3]\n",
    "\n",
    "        kld_weight = kwargs['M_N'] # Account for the minibatch samples from the dataset\n",
    "        recons_loss = F.mse_loss(recons, input)\n",
    "\n",
    "        if self.kl_loss == False or self.kl_loss is None:\n",
    "            kld_loss = 0\n",
    "        elif self.kl_loss.lower() == \"partial\":\n",
    "            kld_loss = torch.mean(torch.sum((1 - log_var.exp()) ** 2, dim = 1), dim = 0)\n",
    "        elif self.kl_loss.lower() == \"full\":\n",
    "            kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"`kl_loss` must be either 'partial' or 'full'\")\n",
    "\n",
    "        archetypal_loss = self.calc_archetypal_loss(mu)\n",
    "\n",
    "        loss = recons_loss + kld_weight * kld_loss + self.archetypal_weight * archetypal_loss\n",
    "\n",
    "        return {'loss': loss, 'Reconstruction_Loss':recons_loss,\n",
    "                'KLD': kld_loss, 'Archetypal_Loss':archetypal_loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
